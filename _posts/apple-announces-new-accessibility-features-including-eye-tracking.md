---
title: 'Apple announces new accessibility features, including Eye Tracking, Music Haptics, and Vocal Shortcuts'
excerpt: 'Coming later this year, Apple’s new accessibility features include Eye Tracking, a way for users to navigate iPad and iPhone with just their eyes.'
coverImage: '/assets/blog/apple-announces-new-accessibility-features-including-eye-tracking/thumbnail.png'
date: '2024-05-28T05:35:07.322Z'
author:
  name: Bhavesh Patil
  picture: '/assets/blog/authors/iambhvsh.png'
ogImage:
  url: '/assets/blog/apple-announces-new-accessibility-features-including-eye-tracking/thumbnail.png'
---

***Apple*** today announced a suite of new accessibility features set to launch later this year. These innovations include Eye Tracking, enabling users with physical disabilities to control their iPad or iPhone using only their eyes. Additionally, Music Haptics will provide an enhanced way for users who are deaf or hard of hearing to experience music through the Taptic Engine on the iPhone. Vocal Shortcuts will allow users to perform tasks by creating custom sounds, while Vehicle Motion Cues aim to mitigate motion sickness when using an iPhone or iPad in a moving vehicle. Further accessibility enhancements will also be integrated into visionOS. These advancements leverage the capabilities of Apple hardware and software, utilizing Apple silicon, artificial intelligence, and machine learning, underscoring Apple’s long-standing commitment to creating inclusive products for all users.

***Tim Cook***, Apple’s CEO, stated, “We deeply believe in the transformative power of innovation to enrich lives. For nearly 40 years, Apple has championed inclusive design by embedding accessibility at the core of our hardware and software. We continuously push the boundaries of technology, and these new features reflect our long-standing commitment to delivering the best possible experience to all our users.”

***Sarah Herrlinger***, Apple’s Senior Director of Global Accessibility Policy and Initiatives, added, “Each year, we break new ground in accessibility. These new features will significantly impact a wide range of users, offering new ways to communicate, control their devices, and navigate the world.”

## Eye Tracking Comes to iPad and iPhone

Powered by artificial intelligence, Eye Tracking provides users with a built-in option to navigate iPads and iPhones using only their eyes. Designed specifically for users with physical disabilities, Eye Tracking utilizes the front-facing camera for quick setup and calibration. With on-device machine learning, all data used to set up and control this feature is kept securely on the device and is not shared with Apple.

Eye Tracking is compatible with both iPadOS and iOS apps and does not require additional hardware or accessories. Users can navigate app elements and use Dwell Control to activate each element, enabling access to functions such as physical buttons, swipes, and other gestures exclusively with their eyes.

## Music Haptics Makes Songs More Accessible

Music Haptics introduces a novel way for users who are deaf or hard of hearing to experience music on the iPhone. When this accessibility feature is enabled, the Taptic Engine in the iPhone produces taps, textures, and refined vibrations that correspond to the audio of the music. Music Haptics is compatible with millions of songs in the Apple Music catalog and will be available as an API for developers to enhance music accessibility in their apps.

## New Features for a Wide Range of Speech

Vocal Shortcuts allow iPhone and iPad users to assign custom utterances that Siri can understand, enabling the launch of shortcuts and completion of complex tasks. Additionally, the Listen for Atypical Speech feature enhances speech recognition for a wider range of speech patterns. Utilizing on-device machine learning, Listen for Atypical Speech is designed for users with acquired or progressive conditions affecting speech, such as cerebral palsy, amyotrophic lateral sclerosis (ALS), or stroke. These features offer a new level of customization and control, building on enhancements introduced in iOS 17 for users who are nonspeaking or at risk of losing their ability to speak.

"Artificial intelligence holds the promise of enhancing speech recognition for millions of individuals with atypical speech, and we are excited that Apple is introducing these new accessibility features to consumers," stated ***Mark Hasegawa-Johnson***, the principal investigator of the Speech Accessibility Project at the Beckman Institute for Advanced Science and Technology at the University of Illinois Urbana-Champaign. "The Speech Accessibility Project was conceived as a collaborative, community-driven initiative to assist companies and universities in bolstering the robustness and efficacy of speech recognition. Apple stands as a prominent advocate for accessibility and has played a crucial role in making the Speech Accessibility Project a reality."

## Vehicle Motion Cues Can Help Reduce Motion Sickness

Introducing Vehicle Motion Cues, a new experience for iPhone and iPad designed to alleviate motion sickness for passengers in transit. Research indicates that motion sickness often arises from a sensory discrepancy between visual perception and physical sensation, hindering some users from comfortably utilizing their iPhone or iPad while in motion. With Vehicle Motion Cues, dynamic dots positioned at the periphery of the screen signify changes in vehicle movement, effectively mitigating sensory conflicts without detracting from the primary content. Leveraging sensors integrated into iPhone and iPad, Vehicle Motion Cues automatically detects when a user is in motion and adjusts accordingly. This feature can be configured to display automatically on iPhone or manually activated and deactivated via Control Center for user convenience.

## CarPlay Gets Voice Control and More Accessibility Updates

CarPlay introduces new accessibility features including Voice Control, Colour Filters, and Sound Recognition. Voice Control enables users to navigate CarPlay and manage apps using voice commands. Sound Recognition allows drivers or passengers who are deaf or hard of hearing to receive alerts for car horns and sirens. For users with color blindness, Colour Filters enhance the CarPlay interface for easier visual navigation, accompanied by additional visual accessibility options such as Bold Text.

## Accessibility Features Coming to visionOS

This year, visionOS will introduce new accessibility features aimed at enhancing user experiences for individuals with diverse needs. Systemwide Live Captions will be integrated to assist everyone, including users who are deaf or hard of hearing, in following spoken dialogue during live conversations and audio playback from various applications. Live Captions for FaceTime in visionOS will enable more users to effortlessly engage in the immersive experience of connecting and collaborating using their Persona.

Additionally, Apple Vision Pro will offer the ability to relocate captions via the window bar during Apple Immersive Video sessions, along with extended support for additional Made for iPhone hearing devices and cochlear hearing processors.

Updates for vision accessibility will include the introduction of Reduce Transparency, Smart Invert, and Dim Flashing Lights functionalities. These enhancements cater to users with low vision or those seeking to mitigate exposure to bright lights and frequent flashing, ensuring a more inclusive and comfortable user experience.

These features complement the array of accessibility options already available in Apple Vision Pro, which boasts a versatile input system and an intuitive interface tailored to accommodate a diverse user base. Functions like VoiceOver, Zoom, and Colour Filters empower users who are blind or have low vision to engage with spatial computing, while features such as Guided Access offer assistance to those with cognitive impairments. Users have the flexibility to interact with Vision Pro using a combination of their eyes, hands, or voice, with accessibility tools like Switch Control, Sound Actions, and Dwell Control providing additional support for individuals with physical disabilities.

***Ryan Hudson-Peralta***, a Detroit-based product designer, accessibility consultant, and cofounder of Equal Accessibility LLC, expressed, "Apple Vision Pro is undoubtedly the most accessible technology I've ever encountered. As someone born without hands and unable to walk, I recognize that the world wasn't designed with me in mind. Witnessing the seamless functionality of visionOS is truly remarkable. It underscores the significance and impact of accessible and inclusive design."

## Additional Updates

- For users who are blind or have low vision, VoiceOver will introduce new voices, a versatile Voice Rotor, customizable volume control, and the ability to personalize VoiceOver keyboard shortcuts on Mac.
- Magnifier will feature a new Reader Mode and the convenience of launching Detection Mode easily with the Action button.
- Braille users will benefit from a streamlined method to initiate and remain in Braille Screen Input for enhanced control and text editing. Additionally, Japanese language support will be available for Braille Screen Input, along with multi-line braille capability using Dot Pad and the option to select different input and output tables.
- For users with low vision, Hover Typing will display larger text in the preferred font and color when typing in a text field.
- For users at risk of losing their ability to speak, Personal Voice will be accessible in Mandarin Chinese. Users who struggle with pronouncing or reading complete sentences can create a Personal Voice using abbreviated phrases.
- For nonspeaking users, Live Speech will feature categorized content and simultaneous compatibility with Live Captions.
- For individuals with physical disabilities, Virtual Trackpad for AssistiveTouch empowers users to control their device by utilizing a resizable trackpad on a small region of the screen.
- Switch Control will include an option to utilize the cameras in iPhone and iPad to recognize finger-tap gestures as switches.
- Voice Control will provide support for custom vocabularies and complex words, enhancing its usability for users across diverse contexts and needs.

The array of updates released by Apple underscores their unwavering commitment to inclusivity and accessibility. These enhancements span a wide spectrum of needs, from individuals with physical disabilities to those who are blind, deaf, or at risk of losing their ability to speak. Features such as Eye Tracking, Music Haptics, and Vehicle Motion Cues demonstrate Apple's dedication to leveraging technology to empower users with diverse abilities.

Moreover, the improvements to VoiceOver, Magnifier, and Braille Screen Input provide greater flexibility and customization for users who are blind or have low vision, while Hover Typing enhances the experience for those with low vision.

The addition of Personal Voice in Mandarin Chinese, Live Speech categories, and Virtual Trackpad for AssistiveTouch further enrich the accessibility ecosystem, offering tailored solutions for a broad range of users.

Overall, these updates not only enhance the usability and functionality of Apple devices but also reinforce the company's commitment to creating products that are truly inclusive and empowering for all users.


> Note: The stated information provided here is based on the description provided and may vary slightly from the actual announcements made by Apple. For more details contact [*iambhvshh@outlook.com*](mailto:iambhvshh@outlook.com)
